{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[<img src=\"https://user-images.githubusercontent.com/79705081/109483674-d3eea600-7a7f-11eb-9a25-58c50da4cde9.png\">](http://edenlibrary.ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plant Segmentation-Background Removal-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "1. Clone the repository.\n",
    "2. Download the necessary datasets from Eden Repository:\n",
    "   1. Broccoli-08/SEP/2019-v1\n",
    "3. Unzip dataset files and remove the zip files.\n",
    "4. Create a folder called 'eden_data'.\n",
    "5. Move the unzipped datasets into this folder.\n",
    "6. The resulting directory structure should be:\n",
    "    * eden_library_notebooks/image_preprocessing/\n",
    "       * plant_segmentation-background_removal-2.ipynb\n",
    "       * eden_data/\n",
    "           * Broccoli-080919-Healthy-zz-V1-XXX...\n",
    "7. Install notebook dependencies by running:\n",
    "    <pre><code>conda env create -f eden_pre-processing.yml</code></pre>\n",
    "8. Open the notebook: jupyter notebook\n",
    "9. Run the code\n",
    "\n",
    "**Note:** If you find any issues while executing the notebook, don't hesitate to open an issue on Github. We will reply you as soon as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background (Go to [Biobliography](#references) for more details)\n",
    "\n",
    "In order to improve the performance of a deep-learning-based system, many times a pre-processing step known as background removal is applied. This technique is supposed to remove as much noise/background from the image, making the object of study appearing as the main part of the picture. Additionally, background removal is not only useful for improving the performance of the deep neural network, but also for reducing <a href=\"https://en.wikipedia.org/wiki/Overfitting\">overffing</a>.\n",
    "\n",
    "In **agriculture**, several works have made use of background removal techniques for achieving a better performance (**Mohanty et al., 2016; McCool et al., 2017; Milioto et al., 2017; Espejo-Garcia et al., 2020**). In this notebook, we are gonna use a specific technique, where the HSV color-space representation (see Figure) will provide us with a better model for separating by thresholding the background and foreground parts of the image.\n",
    "\n",
    "[<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/33/HSV_color_solid_cylinder_saturation_gray.png/800px-HSV_color_solid_cylinder_saturation_gray.png\" style=\"width:20%;\">](https://en.wikipedia.org/wiki/HSL_and_HSV)\n",
    "\n",
    "Specifically, the algorithm can summarised like this:\n",
    "1. Use gaussian blur for remove noise\n",
    "2. Convert color to HSV space\n",
    "3. Create mask\n",
    "4. Create boolean mask\n",
    "5. Apply boolean mask and getting image whithout background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, im_size=(128,128)):\n",
    "    X = []\n",
    "    for im_file in tqdm(glob(path)):\n",
    "        if im_file.lower().endswith(\"jpg\"):\n",
    "            try:\n",
    "                label = im_file.split(\"/\")[1]\n",
    "                im = cv2.imread(im_file)\n",
    "                im = cv2.resize(im, im_size)\n",
    "                im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "                X.append(im)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    \n",
    "    X = np.array(X, np.uint8)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpen_image(image):\n",
    "    image_blurred = cv2.GaussianBlur(image, (0, 0), 3)\n",
    "    image_sharp = cv2.addWeighted(image, 1.5, image_blurred, -0.5, 0)\n",
    "    return image_sharp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:08<00:00, 17.21it/s]\n"
     ]
    }
   ],
   "source": [
    "X = read_data('eden_data/*/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm execution and displaying the segmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_HUE = 0\n",
    "MAX_HUE = 100\n",
    "MIN_SAT = 0\n",
    "MAX_SAT = 220\n",
    "MIN_VAL = 0\n",
    "MAX_VAL = 220\n",
    "\n",
    "LOWER_GREEN = (MIN_HUE, MIN_SAT, MIN_VAL)\n",
    "UPPER_GREEN = (MAX_HUE, MAX_SAT, MAX_VAL)\n",
    "HOMOGENEOUS_SHAPE = (11, 11)\n",
    "BLUR_LEVEL = (5, 5)\n",
    "\n",
    "img = X[0]\n",
    "\n",
    "# 1. Use gaussian blur\n",
    "blur_img = cv2.GaussianBlur(img, BLUR_LEVEL, 0)\n",
    "\n",
    "# 2. Convert to HSV image\n",
    "hsv_img = cv2.cvtColor(blur_img, cv2.COLOR_BGR2HSV)  \n",
    "\n",
    "# 3. Create mask (parameters - green color range)\n",
    "mask = cv2.inRange(hsv_img, LOWER_GREEN, UPPER_GREEN)  \n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, HOMOGENEOUS_SHAPE)\n",
    "mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# 4. Create boolean mask\n",
    "b_mask = mask > 0  \n",
    "\n",
    "# 5. Apply the mask\n",
    "clear = np.zeros_like(img, np.uint8)  # Create empty image\n",
    "clear[b_mask] = img[b_mask]  # Apply boolean mask to the origin image\n",
    "\n",
    "# Show examples\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 3, 1); plt.imshow(img)  # Show the original image\n",
    "plt.subplot(2, 3, 2); plt.imshow(blur_img)  # Blur image\n",
    "plt.subplot(2, 3, 3); plt.imshow(hsv_img)  # HSV image\n",
    "plt.subplot(2, 3, 4); plt.imshow(b_mask)  # Boolean mask\n",
    "plt.subplot(2, 3, 5); plt.imshow(clear)  # Image with removed background\n",
    "plt.subplot(2, 3, 6); plt.imshow(sharpen_image(clear)) # Sharpened version of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biobliography\n",
    "<a id='references'></a>\n",
    "McCool, C., Perez, T., Upcroft, B., 2017. Mixtures of lightweight deep convolutional neural networks: applied to agricultural robotics. IEEE Rob. Autom. Lett. 2 (3), 1344–1351.\n",
    "\n",
    "Milioto, A., Lottes, P., Stachniss, C., 2017. Real-time blob-wise sugar beets vs weeds classification for monitoring fields using convolutional neural networks. Proceedings of the International Conference on Unmanned Aerial Vehicles in Geomatics. Bonn, Germany.\n",
    "\n",
    "Mohanty, S.P., Hughes, D.P., Salathé, M., 2016. Using deep learning for image-based plant disease detection. Front. Plant. Sci. 7.\n",
    "\n",
    "Espejo-García, B., Mylonas, N., Athanasakos, L., Fountas, S., & Vasilakoglou, I. (2020). Towards weeds identification assistance through transfer learning. Comput. Electron. Agric., 171, 105306.\n",
    "\n",
    "https://www.cs.auckland.ac.nz/courses/compsci773s1c/lectures/ImageProcessing-html/topic4.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "This notebook was highly inspired by the work of **Gábor Vecsei** (https://www.kaggle.com/gaborvecsei/plant-seedlings-fun-with-computer-vision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
